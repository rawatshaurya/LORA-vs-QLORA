model_name: "Qwen/Qwen2.5-1.5B-Instruct"
use_4bit: true
bnb_4bit_compute_dtype: "bfloat16"
torch_dtype: "bfloat16"

dataset_type: "strategyqa"
dataset_name: "tasksource/strategy-qa"
dataset_config: null
train_split: "train"
eval_split: "train"     # this dataset card shows train rows; use train subset for now
max_train_samples: 2000
max_eval_samples: 400
seed: 42

max_seq_len: 768

output_dir: "outputs/strategyqa_run_1"
num_train_epochs: 2
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
learning_rate: 2.0e-4
weight_decay: 0.0
warmup_ratio: 0.03
lr_scheduler_type: "cosine"
max_grad_norm: 1.0
logging_steps: 10
save_steps: 200
eval_steps: 200
save_total_limit: 2

lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
target_modules: ["q_proj", "v_proj"]

gen_max_new_tokens: 32
gen_temperature: 0.0
gen_top_p: 1.0
